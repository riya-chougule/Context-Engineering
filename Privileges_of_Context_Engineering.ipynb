{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Description: This demo shows how context engineering can dramatically improve AI responses. It compares answers from a language model asked the same question twice — once without any background information, and once with relevant details retrieved from a small dataset about flight and meeting info. The demo uses vector search to find the right context, then feeds it to the AI to generate smarter, more accurate answers.**"
      ],
      "metadata": {
        "id": "oeTCIoBXw_MS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-community\n",
        "!pip install -q langchain-openai faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_8u_onXMGyS",
        "outputId": "c6dfaed7-b2c6-431c-c0ae-9b160393a743"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<OPENAI API KEY>\"\n",
        "print (\"OpenAI API key imported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na7UKTB5MM17",
        "outputId": "ab67420e-ce61-4360-e6b6-03f687b5b61d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import necessary libraries and tools**"
      ],
      "metadata": {
        "id": "fQX-mXnuvSTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "mjSUQViaMTmW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating our “knowledge base”**"
      ],
      "metadata": {
        "id": "T2XItT2YwD29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    \"Riya's flight to Dallas is on Aug 15 at 10 AM from Newark Liberty International Airport.\",\n",
        "    \"Her preferred seat is window, and she usually checks in 24 hours before departure.\",\n",
        "    \"She has a meeting in NYC on Aug 16 at 2 PM.\"\n",
        "]"
      ],
      "metadata": {
        "id": "plvh-Oj_MqPH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating vector database**"
      ],
      "metadata": {
        "id": "kEmn-ehqwI5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()\n",
        "splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
        "split_docs = splitter.create_documents(docs)\n",
        "vectorstore = FAISS.from_documents(split_docs, embeddings)"
      ],
      "metadata": {
        "id": "bAbPFiV8MvXu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LLM Setup**"
      ],
      "metadata": {
        "id": "LK6KVVCNwT2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0)\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm, retriever=vectorstore.as_retriever(), memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "zsQpSKcfyQbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Comparing “with” and “without” context**"
      ],
      "metadata": {
        "id": "FDJ_AJ-vyVnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Function for Gradio ----\n",
        "def compare_outputs(user_query):\n",
        "    no_context = llm.invoke(user_query).content\n",
        "    with_context = qa_chain.invoke({\"question\": user_query})[\"answer\"]\n",
        "    return no_context, with_context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BKtWKmmwVaM",
        "outputId": "cc8611fa-a427-4595-ab9b-ecfefd5e6f91"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-573039160.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **User Interface**"
      ],
      "metadata": {
        "id": "ctPiWhajwYu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Gradio UI ----\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    # Custom CSS for Clear button\n",
        "    gr.HTML(\"\"\"\n",
        "    <style>\n",
        "      #clear-btn button {\n",
        "        background-color: #ff4d4f !important;\n",
        "        color: white !important;\n",
        "        border: none !important;\n",
        "        font-weight: bold !important;\n",
        "        transition: background-color 0.3s ease !important;\n",
        "      }\n",
        "      #clear-btn button:hover {\n",
        "        background-color: #d9363e !important;\n",
        "      }\n",
        "    </style>\n",
        "    \"\"\")\n",
        "\n",
        "    gr.Markdown(\n",
        "        \"<h2 style='text-align:center'>From Guesswork to Genius</h2>\"\n",
        "        \"<p style='text-align:center'>Watch an AI agent go from “I don’t know” to “I’ve got this”</p>\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            user_input = gr.Textbox(label=\"Ask a question\", placeholder=\"Ask a question\")\n",
        "            with gr.Row():\n",
        "                submit_btn = gr.Button(\"Get Answers\", variant=\"primary\")\n",
        "                clear_btn = gr.Button(\"Clear\", elem_id=\"clear-btn\")\n",
        "\n",
        "        with gr.Column():\n",
        "            no_context_box = gr.Textbox(label=\"Without Context\", lines=4)\n",
        "            with_context_box = gr.Textbox(label=\"With Context\", lines=4)\n",
        "\n",
        "    submit_btn.click(compare_outputs, inputs=user_input, outputs=[no_context_box, with_context_box])\n",
        "    clear_btn.click(lambda: (\"\", \"\", \"\"), outputs=[user_input, no_context_box, with_context_box])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "R_B4_Vv-wa_q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}